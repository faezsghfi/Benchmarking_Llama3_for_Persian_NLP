{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-04T13:25:37.776965Z",
     "iopub.status.busy": "2024-12-04T13:25:37.776126Z",
     "iopub.status.idle": "2024-12-04T13:32:13.189819Z",
     "shell.execute_reply": "2024-12-04T13:32:13.188886Z",
     "shell.execute_reply.started": "2024-12-04T13:25:37.776932Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:809: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dc273743a03419c9605a0e9e4cf09a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/967 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5b69dd749454553aa87079d467709ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "655754554e9c41d4849c71a26ee8576e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "608ba6a4c18a4897abf361a1beaac839",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:471: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbc45f98a85c403fa25b4953923bdc4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/642 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "905008be590e49feab7d652d80ba5f00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e822782f0ab344619fb73d450585c2d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dfb3a11a04540829e7cbeded75b4ee8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00008.safetensors:   0%|          | 0.00/1.89G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41c9d927701d4663859277dd65f3e514",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00008.safetensors:   0%|          | 0.00/1.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42ff7b84288947bebecddacccaf5a53b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00008.safetensors:   0%|          | 0.00/1.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df0e0e28a3524ff285f719b94101d90f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00008.safetensors:   0%|          | 0.00/1.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f1ffe7e951b446f9b13c86459d4aaef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00005-of-00008.safetensors:   0%|          | 0.00/1.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e30aeaa8a67c4753afce4d8e40c2ddb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00006-of-00008.safetensors:   0%|          | 0.00/1.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3ee55b542c54d5280e91c4077688b13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00007-of-00008.safetensors:   0%|          | 0.00/1.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4501eb8ebd7344d79783f266407290f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00008-of-00008.safetensors:   0%|          | 0.00/816M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a91254c51d3f469880b41f06acd9505a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ee54905077246b39f0641b1521aeb00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import transformers\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import os\n",
    "\n",
    "model_id = \"unsloth/Llama-3.2-11B-Vision-bnb-4bit\"\n",
    "# model_id = \"unsloth/llama-3-8b-Instruct-bnb-4bit\"\n",
    "# model_id = \"unsloth/gemma-2-9b-bnb-4bit\"\n",
    "# model_id = \"unsloth/Qwen2-VL-7B-Instruct-bnb-4bit\"\n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    model_kwargs={\n",
    "        \"torch_dtype\": torch.float16,\n",
    "        \"quantization_config\": {\"load_in_4bit\": True},\n",
    "        \"low_cpu_mem_usage\": True,\n",
    "    },\n",
    ")\n",
    "\n",
    "# model_path = \"PartAI/Dorna-Llama3-8B-Instruct\"\n",
    "# token = \"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\"\n",
    "\n",
    "# model_path = \"MaralGPT/Maral-7B-alpha-1\"\n",
    "# token = \"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\"\n",
    "\n",
    "# model_path = \"MehdiHosseiniMoghadam/AVA-Llama-3-V2\"\n",
    "# token = \"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\"\n",
    "\n",
    "# model_path = \"CohereForAI/aya-23-8b\"\n",
    "# token = \"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\"\n",
    "\n",
    "# model_path = \"universitytehran/PersianMind-v1.0\"\n",
    "# token = \"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\"\n",
    "\n",
    "# os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = token\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_path, use_auth_token=token)\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_path,torch_dtype=torch.bfloat16,device_map=\"auto\", use_auth_token=token)\n",
    "# pipeline = transformers.pipeline(\"text-generation\", model=model,model_kwargs={\"torch_dtype\": torch.float16,\"quantization_config\": {\"load_in_4bit\": True},\"low_cpu_mem_usage\": True,}, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T13:32:13.192181Z",
     "iopub.status.busy": "2024-12-04T13:32:13.191488Z",
     "iopub.status.idle": "2024-12-04T13:33:14.334436Z",
     "shell.execute_reply": "2024-12-04T13:33:14.333260Z",
     "shell.execute_reply.started": "2024-12-04T13:32:13.192140Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.10/site-packages (0.43.0)\n",
      "Collecting hazm\n",
      "  Downloading hazm-0.10.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting fasttext-wheel<0.10.0,>=0.9.2 (from hazm)\n",
      "  Downloading fasttext_wheel-0.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
      "Collecting flashtext<3.0,>=2.7 (from hazm)\n",
      "  Downloading flashtext-2.7.tar.gz (14 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: gensim<5.0.0,>=4.3.1 in /opt/conda/lib/python3.10/site-packages (from hazm) (4.3.3)\n",
      "Collecting nltk<4.0.0,>=3.8.1 (from hazm)\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting numpy==1.24.3 (from hazm)\n",
      "  Downloading numpy-1.24.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "Collecting python-crfsuite<0.10.0,>=0.9.9 (from hazm)\n",
      "  Downloading python_crfsuite-0.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: scikit-learn<2.0.0,>=1.2.2 in /opt/conda/lib/python3.10/site-packages (from hazm) (1.2.2)\n",
      "Requirement already satisfied: pybind11>=2.2 in /opt/conda/lib/python3.10/site-packages (from fasttext-wheel<0.10.0,>=0.9.2->hazm) (2.13.6)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from fasttext-wheel<0.10.0,>=0.9.2->hazm) (70.0.0)\n",
      "Collecting scipy<1.14.0,>=1.7.0 (from gensim<5.0.0,>=4.3.1->hazm)\n",
      "  Downloading scipy-1.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /opt/conda/lib/python3.10/site-packages (from gensim<5.0.0,>=4.3.1->hazm) (7.0.4)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->hazm) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->hazm) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->hazm) (2024.5.15)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->hazm) (4.66.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn<2.0.0,>=1.2.2->hazm) (3.5.0)\n",
      "Requirement already satisfied: wrapt in /opt/conda/lib/python3.10/site-packages (from smart-open>=1.8.1->gensim<5.0.0,>=4.3.1->hazm) (1.16.0)\n",
      "Downloading hazm-0.10.0-py3-none-any.whl (892 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m892.6/892.6 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.24.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m82.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading fasttext_wheel-0.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m91.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m57.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_crfsuite-0.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: flashtext\n",
      "  Building wheel for flashtext (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for flashtext: filename=flashtext-2.7-py2.py3-none-any.whl size=9296 sha256=5d8eaac8bebb1aed58ed065998a28cb0e0799ede52911f501956ec15e37723bc\n",
      "  Stored in directory: /root/.cache/pip/wheels/bc/be/39/c37ad168eb2ff644c9685f52554440372129450f0b8ed203dd\n",
      "Successfully built flashtext\n",
      "Installing collected packages: flashtext, python-crfsuite, numpy, nltk, scipy, fasttext-wheel, hazm\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "  Attempting uninstall: nltk\n",
      "    Found existing installation: nltk 3.2.4\n",
      "    Uninstalling nltk-3.2.4:\n",
      "      Successfully uninstalled nltk-3.2.4\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.14.1\n",
      "    Uninstalling scipy-1.14.1:\n",
      "      Successfully uninstalled scipy-1.14.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "cudf 24.10.1 requires cubinlinker, which is not installed.\n",
      "cudf 24.10.1 requires cupy-cuda11x>=12.0.0, which is not installed.\n",
      "cudf 24.10.1 requires libcudf==24.10.*, which is not installed.\n",
      "cudf 24.10.1 requires ptxcompiler, which is not installed.\n",
      "cuml 24.10.0 requires cupy-cuda11x>=12.0.0, which is not installed.\n",
      "cuml 24.10.0 requires cuvs==24.10.*, which is not installed.\n",
      "cuml 24.10.0 requires nvidia-cublas, which is not installed.\n",
      "cuml 24.10.0 requires nvidia-cufft, which is not installed.\n",
      "cuml 24.10.0 requires nvidia-curand, which is not installed.\n",
      "cuml 24.10.0 requires nvidia-cusolver, which is not installed.\n",
      "cuml 24.10.0 requires nvidia-cusparse, which is not installed.\n",
      "dask-cudf 24.10.1 requires cupy-cuda11x>=12.0.0, which is not installed.\n",
      "pylibcudf 24.10.1 requires libcudf==24.10.*, which is not installed.\n",
      "pylibraft 24.10.0 requires nvidia-cublas, which is not installed.\n",
      "pylibraft 24.10.0 requires nvidia-curand, which is not installed.\n",
      "pylibraft 24.10.0 requires nvidia-cusolver, which is not installed.\n",
      "pylibraft 24.10.0 requires nvidia-cusparse, which is not installed.\n",
      "ucxx 0.40.0 requires libucxx==0.40.*, which is not installed.\n",
      "albucore 0.0.20 requires numpy>=1.24.4, but you have numpy 1.24.3 which is incompatible.\n",
      "albumentations 1.4.21 requires numpy>=1.24.4, but you have numpy 1.24.3 which is incompatible.\n",
      "apache-beam 2.46.0 requires cloudpickle~=2.2.1, but you have cloudpickle 3.1.0 which is incompatible.\n",
      "apache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\n",
      "apache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 17.0.0 which is incompatible.\n",
      "bayesian-optimization 2.0.0 requires numpy>=1.25, but you have numpy 1.24.3 which is incompatible.\n",
      "blis 1.0.1 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.24.3 which is incompatible.\n",
      "cesium 0.12.3 requires numpy<3.0,>=2.0, but you have numpy 1.24.3 which is incompatible.\n",
      "cudf 24.10.1 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.6.2.post1 which is incompatible.\n",
      "cudf 24.10.1 requires pandas<2.2.3dev0,>=2.0, but you have pandas 2.2.3 which is incompatible.\n",
      "dask-cudf 24.10.1 requires pandas<2.2.3dev0,>=2.0, but you have pandas 2.2.3 which is incompatible.\n",
      "featuretools 1.31.0 requires numpy>=1.25.0, but you have numpy 1.24.3 which is incompatible.\n",
      "ibis-framework 7.1.0 requires pyarrow<15,>=2, but you have pyarrow 17.0.0 which is incompatible.\n",
      "libpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\n",
      "libpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\n",
      "mlxtend 0.23.3 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\n",
      "plotnine 0.14.3 requires matplotlib>=3.8.0, but you have matplotlib 3.7.5 which is incompatible.\n",
      "preprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.9.1 which is incompatible.\n",
      "pylibcudf 24.10.1 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.6.2.post1 which is incompatible.\n",
      "rmm 24.10.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.6.2.post1 which is incompatible.\n",
      "thinc 8.3.2 requires numpy<2.1.0,>=2.0.0; python_version >= \"3.9\", but you have numpy 1.24.3 which is incompatible.\n",
      "tsfresh 0.20.3 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\n",
      "woodwork 0.31.0 requires numpy>=1.25.0, but you have numpy 1.24.3 which is incompatible.\n",
      "xarray 2024.11.0 requires packaging>=23.2, but you have packaging 21.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed fasttext-wheel-0.9.2 flashtext-2.7 hazm-0.10.0 nltk-3.9.1 numpy-1.24.3 python-crfsuite-0.9.11 scipy-1.13.1\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.46.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.6.2)\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (0.2.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (1.24.3)\n",
      "Collecting numpy\n",
      "  Downloading numpy-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m89.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.3\n",
      "    Uninstalling numpy-1.24.3:\n",
      "      Successfully uninstalled numpy-1.24.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "cudf 24.10.1 requires cubinlinker, which is not installed.\n",
      "cudf 24.10.1 requires cupy-cuda11x>=12.0.0, which is not installed.\n",
      "cudf 24.10.1 requires libcudf==24.10.*, which is not installed.\n",
      "cudf 24.10.1 requires ptxcompiler, which is not installed.\n",
      "cuml 24.10.0 requires cupy-cuda11x>=12.0.0, which is not installed.\n",
      "cuml 24.10.0 requires cuvs==24.10.*, which is not installed.\n",
      "cuml 24.10.0 requires nvidia-cublas, which is not installed.\n",
      "cuml 24.10.0 requires nvidia-cufft, which is not installed.\n",
      "cuml 24.10.0 requires nvidia-curand, which is not installed.\n",
      "cuml 24.10.0 requires nvidia-cusolver, which is not installed.\n",
      "cuml 24.10.0 requires nvidia-cusparse, which is not installed.\n",
      "dask-cudf 24.10.1 requires cupy-cuda11x>=12.0.0, which is not installed.\n",
      "pylibcudf 24.10.1 requires libcudf==24.10.*, which is not installed.\n",
      "pylibraft 24.10.0 requires nvidia-cublas, which is not installed.\n",
      "pylibraft 24.10.0 requires nvidia-curand, which is not installed.\n",
      "pylibraft 24.10.0 requires nvidia-cusolver, which is not installed.\n",
      "pylibraft 24.10.0 requires nvidia-cusparse, which is not installed.\n",
      "ucxx 0.40.0 requires libucxx==0.40.*, which is not installed.\n",
      "apache-beam 2.46.0 requires cloudpickle~=2.2.1, but you have cloudpickle 3.1.0 which is incompatible.\n",
      "apache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\n",
      "apache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 2.1.3 which is incompatible.\n",
      "apache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 17.0.0 which is incompatible.\n",
      "catboost 1.2.7 requires numpy<2.0,>=1.16.0, but you have numpy 2.1.3 which is incompatible.\n",
      "cudf 24.10.1 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.6.2.post1 which is incompatible.\n",
      "cudf 24.10.1 requires pandas<2.2.3dev0,>=2.0, but you have pandas 2.2.3 which is incompatible.\n",
      "dask-cudf 24.10.1 requires pandas<2.2.3dev0,>=2.0, but you have pandas 2.2.3 which is incompatible.\n",
      "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.1.3 which is incompatible.\n",
      "hazm 0.10.0 requires numpy==1.24.3, but you have numpy 2.1.3 which is incompatible.\n",
      "ibis-framework 7.1.0 requires numpy<2,>=1, but you have numpy 2.1.3 which is incompatible.\n",
      "ibis-framework 7.1.0 requires pyarrow<15,>=2, but you have pyarrow 17.0.0 which is incompatible.\n",
      "libpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\n",
      "libpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\n",
      "matplotlib 3.7.5 requires numpy<2,>=1.20, but you have numpy 2.1.3 which is incompatible.\n",
      "mlxtend 0.23.3 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.1.3 which is incompatible.\n",
      "plotnine 0.14.3 requires matplotlib>=3.8.0, but you have matplotlib 3.7.5 which is incompatible.\n",
      "pylibcudf 24.10.1 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.6.2.post1 which is incompatible.\n",
      "rmm 24.10.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.6.2.post1 which is incompatible.\n",
      "tensorflow 2.16.1 requires numpy<2.0.0,>=1.23.5; python_version <= \"3.11\", but you have numpy 2.1.3 which is incompatible.\n",
      "tensorflow-transform 0.14.0 requires numpy<2,>=1.16, but you have numpy 2.1.3 which is incompatible.\n",
      "thinc 8.3.2 requires numpy<2.1.0,>=2.0.0; python_version >= \"3.9\", but you have numpy 2.1.3 which is incompatible.\n",
      "tsfresh 0.20.3 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\n",
      "xarray 2024.11.0 requires packaging>=23.2, but you have packaging 21.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-2.1.3\n"
     ]
    }
   ],
   "source": [
    "! pip install wheel\n",
    "! pip install hazm\n",
    "! pip install transformers\n",
    "! pip install sentencepiece\n",
    "! pip install -U numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T13:33:14.337256Z",
     "iopub.status.busy": "2024-12-04T13:33:14.336312Z",
     "iopub.status.idle": "2024-12-04T13:33:14.343035Z",
     "shell.execute_reply": "2024-12-04T13:33:14.342231Z",
     "shell.execute_reply.started": "2024-12-04T13:33:14.337189Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_inference(prompt):\n",
    "  messages = [\n",
    "    {\"role\": \"system\", \"content\": \".تو یک دستیار ویرایشگر متن های فارسی هستی\"},\n",
    "    {\"role\": \"user\", \"content\": \"\"\"{prompt}\"\"\".format(prompt = prompt)},\n",
    "  ]\n",
    "\n",
    "  prompt = f\"### Human:{prompt}\\n### Assistant:\"\n",
    "\n",
    "\n",
    "  inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "  generation_config = GenerationConfig(\n",
    "        do_sample=True,\n",
    "        top_k=1,\n",
    "        temperature=0.5,\n",
    "        max_new_tokens=2300,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "  outputs = model.generate(**inputs, generation_config=generation_config)\n",
    "  return(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T13:33:14.345533Z",
     "iopub.status.busy": "2024-12-04T13:33:14.345257Z",
     "iopub.status.idle": "2024-12-04T13:33:14.394507Z",
     "shell.execute_reply": "2024-12-04T13:33:14.393642Z",
     "shell.execute_reply.started": "2024-12-04T13:33:14.345508Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "\n",
    "f = open('/kaggle/input/rcdata/eval.json',encoding='utf8')\n",
    "data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T13:33:14.395769Z",
     "iopub.status.busy": "2024-12-04T13:33:14.395523Z",
     "iopub.status.idle": "2024-12-04T13:33:14.401628Z",
     "shell.execute_reply": "2024-12-04T13:33:14.400817Z",
     "shell.execute_reply.started": "2024-12-04T13:33:14.395745Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "rc_data = []\n",
    "for item in data['data']:\n",
    "  for paragraph in item['paragraphs']:\n",
    "    context = paragraph['context']\n",
    "    for qa_item in paragraph['qas']:\n",
    "      question = qa_item['question']\n",
    "      answers = []\n",
    "      for answer in qa_item['answers']:\n",
    "        answers.append(answer['text'])\n",
    "      rc_data.append({\"context\":context,\"question\":question,\"answers\":answers})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T13:43:23.231836Z",
     "iopub.status.busy": "2024-12-04T13:43:23.231475Z",
     "iopub.status.idle": "2024-12-04T13:43:23.237754Z",
     "shell.execute_reply": "2024-12-04T13:43:23.236793Z",
     "shell.execute_reply.started": "2024-12-04T13:43:23.231807Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "570"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rc_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T13:42:22.008722Z",
     "iopub.status.busy": "2024-12-04T13:42:22.007802Z",
     "iopub.status.idle": "2024-12-04T13:42:22.013984Z",
     "shell.execute_reply": "2024-12-04T13:42:22.013259Z",
     "shell.execute_reply.started": "2024-12-04T13:42:22.008684Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "PROMPT_FEW = \"\"\"\n",
    "در این وظیفه به تو یک متن فارسی داده میشود. این متن را به دقت بخوان و بعد به سوالی که به تو داده میشود با توجه به متن داده شده در کوتاه ترین حالت ممکن پاسخ بده. \n",
    "برای فهم بیشتر به نمونه داده شده دقت کن. \n",
    "متن: '''هیدروسفالی(به انگلیسی: Hydrocephalus) در پزشکی به وضعیتی گفته می‌شود که مایع مغزی-نخاعی تولید شده در شبکه کوروئید٬ بیش از اندازه در بطن‌های مغزی و دیگر حفره‌های مغز انباشته گردد و منجر به افزایش حجم آن‌ها شود. این افزایش حجم اشغال شده توسط مایع در سیستم عصبی مرکزی و بویژه مغز می‌تواند ناشی از اختلال در توزیع٬ تشکیل٬ جریان یا جذب مایع مغزی-نخاعی باشد و پی‌آمد آن افزایش فشار درون جمجمه و آسیب‌های مغزی و حتی مرگ است. هیدروسفالی در کودکان زیر دو سال به‌خاطر بازبودن سوچورهای کرانیکال(درزهای استخوان جمجمه) منجربه بزرگ شدن غیرطبیعی جمجمه شده ولی در بزرگ‌سالان با اختلال در راه رفتن و حافظه نمود میابد. هیدروسفالی در کودکان بیشتر بعلت ناهنجاری مادرزادی کیاری*٬ تنگی در مجرای مغزی(سیلویوس) مادرزادی یا خونریزی و عفونت نوزادی داخل بطنی پدید می‌آید. بزرگ شدن بالای سر همراه‌با نازک شدن استخوان‌های جمجمه و جدا شدن سوچورها و در موارد پیشرفته‌تر آتروفی اپتیک و اختلال در حرکت چشم‌ها و مشکل در تعادل و راه رفتن کودک٬ دیده می‌شود.'''\n",
    "\n",
    "سوال: '''هیدروسفالی چه نوع بیماری است؟'''\n",
    "پاسخ: هیدروسفالی یک بیماری مغزی است.\n",
    "\n",
    "\n",
    "متن: '''بوداپـِست پایتخت، بزرگترین و پرجمعیت‌ترین شهر کشور مجارستان و مرکز سیاسی، فرهنگی، تجاری، صنعتی و ترابری این کشور است. بوداپست از سه بخشِ اُبودا (بودای قدیم)، بودا (تپه ای و در کرانهٔ باختری دانوب)، و پست (خلاف بودا کاملاً تخت و سمت خاوری رود) تشکیل شده‌است. جمعیت بوداپست طبق آمار اول ژانویهٔ سال ۲۰۱۹ برابر با ۱٬۷۵۲٬۲۸۶ نفر بوده‌است. مساحت شهر حدود ۵۲۵ کیلومتر مربع و یک واحد مستقل در تقسیمات کشوری مجارستان است.'''\n",
    "سوال: '''بوداپست در کدام کشور است؟'''\n",
    "پاسخ: مجارستان\n",
    "\n",
    "\n",
    "متن:'''سه کشور اروپایی (EU 3) یا سه کشور بزرگ اروپا (به انگلیسی: The EU Big Three)‏ اصطلاحاً اشاره به ۳ کشور قاره اروپا یعنی فرانسه، آلمان و بریتانیا دارد.'''\n",
    "سوال: '''3eu کدام کشور است؟'''\n",
    "پاسخ:['فرانسه، آلمان و بریتانیا']\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T13:47:35.920611Z",
     "iopub.status.busy": "2024-12-04T13:47:35.920331Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i:  0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "all_response = []\n",
    "index = 0\n",
    "for  row in rc_data:\n",
    "    print('i: ',index)\n",
    "    context = row['context']\n",
    "    question = row['question']\n",
    "    answers = row['answers']\n",
    "\n",
    "    prompt_arman = f\"\"\"\n",
    "    شرح وظیفه:\n",
    "    {PROMPT_FEW}\n",
    "\n",
    "     حالا به سوالات زیر با توجه به متن داده شده پاسخ بده\n",
    "    متن:{context}\n",
    "    سوال:{question}\n",
    "    پاسخ:{answer}\n",
    "    \"\"\"\n",
    "    response = get_inference(prompt_arman)\n",
    "    index, = index,+1\n",
    "    all_response.append({'context':context , 'question':question , 'answer':answer})\n",
    "    np.save(f'/kaggle/working/rc_maral.npy', np.array(all_response, dtype=object))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6227466,
     "sourceId": 10097588,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
