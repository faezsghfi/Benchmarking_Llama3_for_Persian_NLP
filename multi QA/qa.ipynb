{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-03T09:17:22.140042Z",
     "iopub.status.busy": "2024-12-03T09:17:22.139072Z",
     "iopub.status.idle": "2024-12-03T09:17:44.797909Z",
     "shell.execute_reply": "2024-12-03T09:17:44.796731Z",
     "shell.execute_reply.started": "2024-12-03T09:17:22.140004Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.46.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.6.2)\n",
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (1.1.1)\n",
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.26.2)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.5)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.4.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (3.15.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (2024.6.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.6.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Downloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl (122.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.4/122.4 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: bitsandbytes\n",
      "Successfully installed bitsandbytes-0.44.1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install -U \"transformers\" --upgrade\n",
    "!pip install accelerate bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T09:18:11.588562Z",
     "iopub.status.busy": "2024-12-03T09:18:11.587697Z",
     "iopub.status.idle": "2024-12-03T09:18:11.593104Z",
     "shell.execute_reply": "2024-12-03T09:18:11.592288Z",
     "shell.execute_reply.started": "2024-12-03T09:18:11.588527Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM , GenerationConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T09:18:17.292200Z",
     "iopub.status.busy": "2024-12-03T09:18:17.291509Z",
     "iopub.status.idle": "2024-12-03T09:25:00.014526Z",
     "shell.execute_reply": "2024-12-03T09:25:00.013825Z",
     "shell.execute_reply.started": "2024-12-03T09:18:17.292164Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:809: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90beaada1b04400e9e7636a1ad447af0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/967 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f1e14564021427bb8ecbfadbc260c68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8b5432c013c4f5e928a06ce2a3ea143",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ba46ee698b342dbaa76e7fba0ec0b0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:471: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1154d1dad7534c339a44818231fa82f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/642 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2a1ce6b86a4416fa4df4c3b7a112dd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adc134fce788492ea91fc496454d5710",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e137cac958a94e67986fc90d001b2c9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00008.safetensors:   0%|          | 0.00/1.89G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f22c8627e2b14a1ab08b14c5b17535c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00008.safetensors:   0%|          | 0.00/1.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d302a5794ae4aa49925814917f621d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00008.safetensors:   0%|          | 0.00/1.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85cb655f8df54fab801247ebdd3b7f0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00008.safetensors:   0%|          | 0.00/1.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f930fac12c364869a271f5427083e226",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00005-of-00008.safetensors:   0%|          | 0.00/1.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb2a4e4b5bb44c409d72373d5b0982c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00006-of-00008.safetensors:   0%|          | 0.00/1.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5850c9245f494cc5b6531f8274d5cc9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00007-of-00008.safetensors:   0%|          | 0.00/1.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dc80b93b16b4316b335b6e37091ea69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00008-of-00008.safetensors:   0%|          | 0.00/816M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14bc5ff727d6495c8fe5eb8d496048d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11930185e3ee40c1829fe89a5a3ab8d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import transformers\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import os\n",
    "\n",
    "model_id = \"unsloth/Llama-3.2-11B-Vision-bnb-4bit\"\n",
    "# model_id = \"unsloth/llama-3-8b-Instruct-bnb-4bit\"\n",
    "# model_id = \"unsloth/gemma-2-9b-bnb-4bit\"\n",
    "# model_id = \"unsloth/Qwen2-VL-7B-Instruct-bnb-4bit\"\n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    model_kwargs={\n",
    "        \"torch_dtype\": torch.float16,\n",
    "        \"quantization_config\": {\"load_in_4bit\": True},\n",
    "        \"low_cpu_mem_usage\": True,\n",
    "    },\n",
    ")\n",
    "\n",
    "# model_path = \"PartAI/Dorna-Llama3-8B-Instruct\"\n",
    "# token = \"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\"\n",
    "\n",
    "# model_path = \"MaralGPT/Maral-7B-alpha-1\"\n",
    "# token = \"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\"\n",
    "\n",
    "# model_path = \"MehdiHosseiniMoghadam/AVA-Llama-3-V2\"\n",
    "# token = \"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\"\n",
    "\n",
    "# model_path = \"CohereForAI/aya-23-8b\"\n",
    "# token = \"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\"\n",
    "\n",
    "# model_path = \"universitytehran/PersianMind-v1.0\"\n",
    "# token = \"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\"\n",
    "\n",
    "# os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = token\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_path, use_auth_token=token)\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_path,torch_dtype=torch.bfloat16,device_map=\"auto\", use_auth_token=token)\n",
    "# pipeline = transformers.pipeline(\"text-generation\", model=model,model_kwargs={\"torch_dtype\": torch.float16,\"quantization_config\": {\"load_in_4bit\": True},\"low_cpu_mem_usage\": True,}, tokenizer=tokenizer)s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T09:26:39.867185Z",
     "iopub.status.busy": "2024-12-03T09:26:39.866459Z",
     "iopub.status.idle": "2024-12-03T09:26:39.939845Z",
     "shell.execute_reply": "2024-12-03T09:26:39.938984Z",
     "shell.execute_reply.started": "2024-12-03T09:26:39.867152Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>candidates</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>كدام كلمه جمع است</td>\n",
       "      <td>پهلوان,مازندران,يزدان,ديوان</td>\n",
       "      <td>ديوان</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>متضاد کلمات مورد سؤال چیست؟ رام</td>\n",
       "      <td>سرکش,بیباك,خشن,آشفته</td>\n",
       "      <td>سرکش</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>بزرگترین نسخ نویس ایرانی چه نام دارد؟</td>\n",
       "      <td>میر علی تبریزی,ابن مقله شیرازی,میرزا احمد تبری...</td>\n",
       "      <td>میر علی تبریزی</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>مفهوم کدام بیت با ابیات دیگر متفاوت است؟</td>\n",
       "      <td>یه هر غمی که رسد از تو خاطرم شاد است که بنده‌ی...</td>\n",
       "      <td>غم مخور ز آن که به یک حال نمانده است جهان شادی...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>متضاد کدر</td>\n",
       "      <td>درخشان,شفاف,زلال,صاف</td>\n",
       "      <td>شفاف</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>متضاد ممانعت</td>\n",
       "      <td>تسهیل,تجویز,تسریع, ترغیب</td>\n",
       "      <td>تجویز</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>در « زنگ آفرینش » معلم چه آرزوهایی کرد ؟</td>\n",
       "      <td>شبانه روز زائر حرم بودن,به آرزوی خود رسیدن بچه...</td>\n",
       "      <td>پیغمبر بهار شدن</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>با حروف تر، ا،ب،ز،و،ه چند کلمه از کلمات زیر را...</td>\n",
       "      <td>یک,دو,سه,چهار</td>\n",
       "      <td>دو</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>هدف از سایه روشن در نقاشی ؟</td>\n",
       "      <td>معنای مطلق سایه و روشنایی,تاریکی و روشنایی,بیا...</td>\n",
       "      <td>بیان حجم</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>از حرف «و» در مصراع «چه خیال‌ها گذر کرد و گذر ...</td>\n",
       "      <td>زیرا,اما,اگر,چون</td>\n",
       "      <td>زیرا</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question  \\\n",
       "0                                    كدام كلمه جمع است   \n",
       "1                      متضاد کلمات مورد سؤال چیست؟ رام   \n",
       "2                بزرگترین نسخ نویس ایرانی چه نام دارد؟   \n",
       "3             مفهوم کدام بیت با ابیات دیگر متفاوت است؟   \n",
       "4                                            متضاد کدر   \n",
       "..                                                 ...   \n",
       "195                                       متضاد ممانعت   \n",
       "196           در « زنگ آفرینش » معلم چه آرزوهایی کرد ؟   \n",
       "197  با حروف تر، ا،ب،ز،و،ه چند کلمه از کلمات زیر را...   \n",
       "198                        هدف از سایه روشن در نقاشی ؟   \n",
       "199  از حرف «و» در مصراع «چه خیال‌ها گذر کرد و گذر ...   \n",
       "\n",
       "                                            candidates  \\\n",
       "0                          پهلوان,مازندران,يزدان,ديوان   \n",
       "1                                 سرکش,بیباك,خشن,آشفته   \n",
       "2    میر علی تبریزی,ابن مقله شیرازی,میرزا احمد تبری...   \n",
       "3    یه هر غمی که رسد از تو خاطرم شاد است که بنده‌ی...   \n",
       "4                                 درخشان,شفاف,زلال,صاف   \n",
       "..                                                 ...   \n",
       "195                           تسهیل,تجویز,تسریع, ترغیب   \n",
       "196  شبانه روز زائر حرم بودن,به آرزوی خود رسیدن بچه...   \n",
       "197                                      یک,دو,سه,چهار   \n",
       "198  معنای مطلق سایه و روشنایی,تاریکی و روشنایی,بیا...   \n",
       "199                                   زیرا,اما,اگر,چون   \n",
       "\n",
       "                                                target  \n",
       "0                                                ديوان  \n",
       "1                                                 سرکش  \n",
       "2                                       میر علی تبریزی  \n",
       "3    غم مخور ز آن که به یک حال نمانده است جهان شادی...  \n",
       "4                                                 شفاف  \n",
       "..                                                 ...  \n",
       "195                                              تجویز  \n",
       "196                                    پیغمبر بهار شدن  \n",
       "197                                                 دو  \n",
       "198                                           بیان حجم  \n",
       "199                                               زیرا  \n",
       "\n",
       "[200 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "file_path = 'data/literature.jsonl'\n",
    "dataset = pd.read_json(file_path, lines=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T09:26:46.492882Z",
     "iopub.status.busy": "2024-12-03T09:26:46.492252Z",
     "iopub.status.idle": "2024-12-03T09:26:46.534517Z",
     "shell.execute_reply": "2024-12-03T09:26:46.533606Z",
     "shell.execute_reply.started": "2024-12-03T09:26:46.492846Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23/2868252127.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  test_prompt = rayan_dataset.groupby('label').apply(lambda x: x.sample(n_test_sample))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ANGRY</th>\n",
       "      <th>841</th>\n",
       "      <td>حوصلم سر رفته و دوس دارم با دوستام برم بیرون ا...</td>\n",
       "      <td>ANGRY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FEAR</th>\n",
       "      <th>306</th>\n",
       "      <td>زندگی تو ایران دیگه داره فیلم ترسناک میشه</td>\n",
       "      <td>FEAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HAPPY</th>\n",
       "      <th>864</th>\n",
       "      <td>محمد صلاح در پاسخ به سؤال یک خبرنگار که از او ...</td>\n",
       "      <td>HAPPY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HATE</th>\n",
       "      <th>593</th>\n",
       "      <td>#الوبگوازادی واکنش پاسدار رنگ ولعاب شده نظام و...</td>\n",
       "      <td>HATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OTHER</th>\n",
       "      <th>725</th>\n",
       "      <td>» نه ببین همون کاری که من میکنمو بکن! این کارا...</td>\n",
       "      <td>OTHER</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        text  label\n",
       "label                                                              \n",
       "ANGRY 841  حوصلم سر رفته و دوس دارم با دوستام برم بیرون ا...  ANGRY\n",
       "FEAR  306          زندگی تو ایران دیگه داره فیلم ترسناک میشه   FEAR\n",
       "HAPPY 864  محمد صلاح در پاسخ به سؤال یک خبرنگار که از او ...  HAPPY\n",
       "HATE  593  #الوبگوازادی واکنش پاسدار رنگ ولعاب شده نظام و...   HATE\n",
       "OTHER 725  » نه ببین همون کاری که من میکنمو بکن! این کارا...  OTHER"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_test_sample = 1\n",
    "test_prompt = rayan_dataset.groupby('label').apply(lambda x: x.sample(n_test_sample))\n",
    "\n",
    "test_prompt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T09:26:50.563170Z",
     "iopub.status.busy": "2024-12-03T09:26:50.562829Z",
     "iopub.status.idle": "2024-12-03T09:26:50.568941Z",
     "shell.execute_reply": "2024-12-03T09:26:50.567932Z",
     "shell.execute_reply.started": "2024-12-03T09:26:50.563140Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_inference(prompt):\n",
    "  messages = [\n",
    "    {\"role\": \"system\", \"content\": \".تو یک دستیار ویرایشگر متن های فارسی هستی\"},\n",
    "    {\"role\": \"user\", \"content\": \"\"\"{prompt}\"\"\".format(prompt = prompt)},\n",
    "  ]\n",
    "\n",
    "  prompt = f\"### Human:{prompt}\\n### Assistant:\"\n",
    "\n",
    "\n",
    "  inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "  generation_config = GenerationConfig(\n",
    "        do_sample=True,\n",
    "        top_k=1,\n",
    "        temperature=0.5,\n",
    "        max_new_tokens=300,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "  outputs = model.generate(**inputs, generation_config=generation_config)\n",
    "  return(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "PROMPT_FEW = \"\"\"\n",
    "در ادامه به تو یک سوال نشان داده می شود. تو باید از بین پاسخ های ارائه شده گزینه درست را انتخاب کنید.\n",
    "به مثالهای زیر توجه کن:\n",
    "\n",
    "  مثال 1:\n",
    "      'question': 'عدد ۶ یک عدد کامل نامیده می\\u200cشود، زیرا برابر است با مجموع مقسوم علیه\\u200cهایش به استثنای خود عدد ۶ کدامیک از عددهای زیر عدد کامل است؟'\n",
    "      'candidates': ['۱۲', '۲۸', '۳۶', '۱۶']\n",
    "      'answer': '2'\n",
    "\n",
    "\n",
    "  مثال 2:\n",
    "      'question': ' از ابتدای تاریخ، کدام گزینه زیر انسانها را به همکاری با یکدیگر واداشته است؟'\n",
    "      'candidates': ['ضرورتهای زندگی اجتماعی', 'اهداف سیاسی دولت- شهرها', 'تشکیل اجتماعات انسانی', 'فرهنگ پذیری']\n",
    "      'answer': '1'\n",
    "\n",
    "\n",
    "  مثال 3:\n",
    "      'question': 'كدام كلمه جمع است'\n",
    "      'candidates': ['پهلوان', 'مازندران', 'يزدان', 'ديوان']\n",
    "      'answer': '4'\n",
    "\n",
    "\n",
    "  مثال 4:\n",
    "      'question': 'وسیع ترین کشور جهان کدام است؟',\n",
    "      'candidates': ['آمریکا', 'کانادا', 'روسیه', 'چین'],\n",
    "      'answer': '3'\n",
    "\n",
    "\n",
    "  مثال 5:\n",
    "      'question': 'در کدام گزینه، آثار موسوی گرما رودی تماما درست است؟',\n",
    "      'candidates': ['سرود رگبار، دستچين، عبور، چمن لاله',\n",
    "      'چمن لاله، خطّ خون، مثل درخت در شب باران، سرود رگبار',\n",
    "      'در سايه سار نخل ولايت، از بودن و سرودن، خطّ خون، عبور',\n",
    "       'تاناكجا، دستچين، در سايه سار نخل ولايت، از بودن و سرودن'],\n",
    "      'answer': '1'\n",
    "\n",
    "\n",
    "\n",
    "  فرمت خروجی:\n",
    "  فرمت خروجی شما باید یک تاپل  باشد، که در آن هر تاپل از سوال و پاسخهای کاندید و پاسخ تشخیص داده شده تشکیل شده باشد.\n",
    "\n",
    "  \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T09:27:02.764143Z",
     "iopub.status.busy": "2024-12-03T09:27:02.763788Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i:  0\n",
      "i:  1\n",
      "i:  2\n",
      "i:  3\n",
      "i:  4\n",
      "i:  5\n",
      "i:  6\n",
      "i:  7\n",
      "i:  8\n",
      "i:  9\n",
      "i:  10\n",
      "i:  11\n",
      "i:  12\n",
      "i:  13\n",
      "i:  14\n",
      "i:  15\n",
      "i:  16\n",
      "i:  17\n",
      "i:  18\n",
      "i:  19\n",
      "i:  20\n",
      "i:  21\n",
      "i:  22\n",
      "i:  23\n",
      "i:  24\n",
      "i:  25\n",
      "i:  26\n",
      "i:  27\n",
      "i:  28\n",
      "i:  29\n",
      "i:  30\n",
      "i:  31\n",
      "i:  32\n",
      "i:  33\n",
      "i:  34\n",
      "i:  35\n",
      "i:  36\n",
      "i:  37\n",
      "i:  38\n",
      "i:  39\n",
      "i:  40\n",
      "i:  41\n",
      "i:  42\n",
      "i:  43\n",
      "i:  44\n",
      "i:  45\n",
      "i:  46\n",
      "i:  47\n",
      "i:  48\n",
      "i:  49\n",
      "i:  50\n",
      "i:  51\n",
      "i:  52\n",
      "i:  53\n",
      "i:  54\n",
      "i:  55\n",
      "i:  56\n",
      "i:  57\n",
      "i:  58\n",
      "i:  59\n",
      "i:  60\n",
      "i:  61\n",
      "i:  62\n",
      "i:  63\n",
      "i:  64\n",
      "i:  65\n",
      "i:  66\n",
      "i:  67\n",
      "i:  68\n",
      "i:  69\n",
      "i:  70\n",
      "i:  71\n",
      "i:  72\n",
      "i:  73\n",
      "i:  74\n",
      "i:  75\n",
      "i:  76\n",
      "i:  77\n",
      "i:  78\n",
      "i:  79\n",
      "i:  80\n",
      "i:  81\n",
      "i:  82\n",
      "i:  83\n",
      "i:  84\n",
      "i:  85\n",
      "i:  86\n",
      "i:  87\n",
      "i:  88\n",
      "i:  89\n",
      "i:  90\n",
      "i:  91\n",
      "i:  92\n",
      "i:  93\n",
      "i:  94\n",
      "i:  95\n",
      "i:  96\n",
      "i:  97\n",
      "i:  98\n",
      "i:  99\n",
      "i:  100\n",
      "i:  101\n",
      "i:  102\n",
      "i:  103\n",
      "i:  104\n",
      "i:  105\n",
      "i:  106\n",
      "i:  107\n",
      "i:  108\n",
      "i:  109\n",
      "i:  110\n",
      "i:  111\n",
      "i:  112\n",
      "i:  113\n",
      "i:  114\n",
      "i:  115\n",
      "i:  116\n",
      "i:  117\n",
      "i:  118\n",
      "i:  119\n",
      "i:  120\n",
      "i:  121\n",
      "i:  122\n",
      "i:  123\n",
      "i:  124\n",
      "i:  125\n",
      "i:  126\n",
      "i:  127\n",
      "i:  128\n",
      "i:  129\n",
      "i:  130\n",
      "i:  131\n",
      "i:  132\n",
      "i:  133\n",
      "i:  134\n",
      "i:  135\n",
      "i:  136\n",
      "i:  137\n",
      "i:  138\n",
      "i:  139\n",
      "i:  140\n",
      "i:  141\n",
      "i:  142\n",
      "i:  143\n",
      "i:  144\n",
      "i:  145\n",
      "i:  146\n",
      "i:  147\n",
      "i:  148\n",
      "i:  149\n",
      "i:  150\n",
      "i:  151\n",
      "i:  152\n",
      "i:  153\n",
      "i:  154\n",
      "i:  155\n",
      "i:  156\n",
      "i:  157\n",
      "i:  158\n",
      "i:  159\n",
      "i:  160\n",
      "i:  161\n",
      "i:  162\n",
      "i:  163\n",
      "i:  164\n",
      "i:  165\n",
      "i:  166\n",
      "i:  167\n",
      "i:  168\n",
      "i:  169\n",
      "i:  170\n",
      "i:  171\n",
      "i:  172\n",
      "i:  173\n",
      "i:  174\n",
      "i:  175\n",
      "i:  176\n",
      "i:  177\n",
      "i:  178\n",
      "i:  179\n",
      "i:  180\n",
      "i:  181\n",
      "i:  182\n",
      "i:  183\n",
      "i:  184\n",
      "i:  185\n",
      "i:  186\n",
      "i:  187\n",
      "i:  188\n",
      "i:  189\n",
      "i:  190\n",
      "i:  191\n",
      "i:  192\n",
      "i:  193\n",
      "i:  194\n",
      "i:  195\n",
      "i:  196\n",
      "i:  197\n",
      "i:  198\n",
      "i:  199\n",
      "i:  200\n",
      "i:  201\n",
      "i:  202\n",
      "i:  203\n",
      "i:  204\n",
      "i:  205\n",
      "i:  206\n",
      "i:  207\n",
      "i:  208\n",
      "i:  209\n",
      "i:  210\n",
      "i:  211\n",
      "i:  212\n",
      "i:  213\n",
      "i:  214\n",
      "i:  215\n",
      "i:  216\n",
      "i:  217\n",
      "i:  218\n",
      "i:  219\n",
      "i:  220\n",
      "i:  221\n",
      "i:  222\n",
      "i:  223\n",
      "i:  224\n",
      "i:  225\n",
      "i:  226\n",
      "i:  227\n",
      "i:  228\n",
      "i:  229\n",
      "i:  230\n",
      "i:  231\n",
      "i:  232\n",
      "i:  233\n",
      "i:  234\n",
      "i:  235\n",
      "i:  236\n",
      "i:  237\n",
      "i:  238\n",
      "i:  239\n",
      "i:  240\n",
      "i:  241\n",
      "i:  242\n",
      "i:  243\n",
      "i:  244\n",
      "i:  245\n",
      "i:  246\n",
      "i:  247\n",
      "i:  248\n",
      "i:  249\n",
      "i:  250\n",
      "i:  251\n",
      "i:  252\n",
      "i:  253\n",
      "i:  254\n",
      "i:  255\n",
      "i:  256\n",
      "i:  257\n",
      "i:  258\n",
      "i:  259\n",
      "i:  260\n",
      "i:  261\n",
      "i:  262\n",
      "i:  263\n",
      "i:  264\n",
      "i:  265\n",
      "i:  266\n",
      "i:  267\n",
      "i:  268\n",
      "i:  269\n",
      "i:  270\n",
      "i:  271\n",
      "i:  272\n",
      "i:  273\n",
      "i:  274\n",
      "i:  275\n",
      "i:  276\n",
      "i:  277\n",
      "i:  278\n",
      "i:  279\n",
      "i:  280\n",
      "i:  281\n",
      "i:  282\n",
      "i:  283\n",
      "i:  284\n",
      "i:  285\n",
      "i:  286\n",
      "i:  287\n",
      "i:  288\n",
      "i:  289\n",
      "i:  290\n",
      "i:  291\n",
      "i:  292\n",
      "i:  293\n",
      "i:  294\n",
      "i:  295\n",
      "i:  296\n",
      "i:  297\n",
      "i:  298\n",
      "i:  299\n",
      "i:  300\n",
      "i:  301\n",
      "i:  302\n",
      "i:  303\n",
      "i:  304\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "all_response = []\n",
    "\n",
    "for index, row in enumerate(questions['math_and_logic']):\n",
    "    print('i: ',index)\n",
    "    quest = row['question']\n",
    "    candid = row['candidates']\n",
    "    ans = row['answer']\n",
    "\n",
    "    prompt_arman = f\"\"\"\n",
    "    شرح وظیفه:\n",
    "    {PROMPT_FEW}\n",
    "\n",
    "     سوال:\n",
    "    {quest}\n",
    "\n",
    "    گزینه ها:\n",
    "    {ans}\n",
    "    \"\"\"\n",
    "    response = get_inference(prompt_arman)\n",
    "\n",
    "    all_response.append({'quest':quest ,'candid':candid, 'ans':ans , 'response':response})\n",
    "    np.save(f'/kaggle/working/qa_maral.npy', np.array(all_response, dtype=object))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6212575,
     "sourceId": 10078063,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
