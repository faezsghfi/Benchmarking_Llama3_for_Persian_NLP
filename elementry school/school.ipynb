{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-06T17:56:15.895318Z",
     "iopub.status.busy": "2024-12-06T17:56:15.894955Z",
     "iopub.status.idle": "2024-12-06T17:56:16.227357Z",
     "shell.execute_reply": "2024-12-06T17:56:16.226682Z",
     "shell.execute_reply.started": "2024-12-06T17:56:15.895280Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T17:57:16.111765Z",
     "iopub.status.busy": "2024-12-06T17:57:16.111049Z",
     "iopub.status.idle": "2024-12-06T17:57:47.345446Z",
     "shell.execute_reply": "2024-12-06T17:57:47.344499Z",
     "shell.execute_reply.started": "2024-12-06T17:57:16.111729Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.46.3)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.47.0-py3-none-any.whl.metadata (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.6.2)\n",
      "Downloading transformers-4.47.0-py3-none-any.whl (10.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m81.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tokenizers, transformers\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.20.3\n",
      "    Uninstalling tokenizers-0.20.3:\n",
      "      Successfully uninstalled tokenizers-0.20.3\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.46.3\n",
      "    Uninstalling transformers-4.46.3:\n",
      "      Successfully uninstalled transformers-4.46.3\n",
      "Successfully installed tokenizers-0.21.0 transformers-4.47.0\n",
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (1.1.1)\n",
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.45.0-py3-none-manylinux_2_24_x86_64.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.26.2)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.5)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.4.0)\n",
      "Requirement already satisfied: typing_extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (4.12.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (3.15.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (2024.6.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.4)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.6.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Downloading bitsandbytes-0.45.0-py3-none-manylinux_2_24_x86_64.whl (69.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: bitsandbytes\n",
      "Successfully installed bitsandbytes-0.45.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -U \"transformers\" --upgrade\n",
    "!pip install accelerate bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T17:59:01.803210Z",
     "iopub.status.busy": "2024-12-06T17:59:01.802551Z",
     "iopub.status.idle": "2024-12-06T18:05:35.733323Z",
     "shell.execute_reply": "2024-12-06T18:05:35.732547Z",
     "shell.execute_reply.started": "2024-12-06T17:59:01.803163Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:810: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e14e9263160a42aea6eaed079a6dce28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/967 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "939d7e37129a47d2a419d245f837b4f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50649ca144e746648310866c8ec9029a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a51c8a912bfa4177beb20bcf7556ad79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:471: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad370a6ef5f142f6a7c5b99aa700ae08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/642 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33400eec739041be8098f3d30e2e0d5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0afab2d9c2b74f83b7ff00b2bacd86b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cb37163d38f4a0da9f01ae05512128f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00008.safetensors:   0%|          | 0.00/1.89G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3679a966deda452a9f8ae4b05b75c9a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00008.safetensors:   0%|          | 0.00/1.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bb9b1420ebf4be6bcdbbe87a4f747f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00008.safetensors:   0%|          | 0.00/1.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9046df12d3b747608f1fc9f21ed4fd82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00008.safetensors:   0%|          | 0.00/1.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a82c03310534992b2d6db1e8c29db17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00005-of-00008.safetensors:   0%|          | 0.00/1.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8676c78feb5b4f7bae6d4601313d20af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00006-of-00008.safetensors:   0%|          | 0.00/1.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b481123a79e3428c8e0e9c63fb76c2db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00007-of-00008.safetensors:   0%|          | 0.00/1.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31ff8e49225f4240a89480194eb48941",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00008-of-00008.safetensors:   0%|          | 0.00/816M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "367075ad611a4b4f9ecaba15f697d2e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f70a99240b6148819b2188b3c8c04dc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import os\n",
    "\n",
    "model_id = \"unsloth/Llama-3.2-11B-Vision-bnb-4bit\"\n",
    "# model_id = \"unsloth/llama-3-8b-Instruct-bnb-4bit\"\n",
    "# model_id = \"unsloth/gemma-2-9b-bnb-4bit\"\n",
    "# model_id = \"unsloth/Qwen2-VL-7B-Instruct-bnb-4bit\"\n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    model_kwargs={\n",
    "        \"torch_dtype\": torch.float16,\n",
    "        \"quantization_config\": {\"load_in_4bit\": True},\n",
    "        \"low_cpu_mem_usage\": True,\n",
    "    },\n",
    ")\n",
    "\n",
    "# model_path = \"PartAI/Dorna-Llama3-8B-Instruct\"\n",
    "# token = \"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\"\n",
    "\n",
    "# model_path = \"MaralGPT/Maral-7B-alpha-1\"\n",
    "# token = \"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\"\n",
    "\n",
    "# model_path = \"MehdiHosseiniMoghadam/AVA-Llama-3-V2\"\n",
    "# token = \"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\"\n",
    "\n",
    "# model_path = \"CohereForAI/aya-23-8b\"\n",
    "# token = \"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\"\n",
    "\n",
    "# model_path = \"universitytehran/PersianMind-v1.0\"\n",
    "# token = \"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\"\n",
    "\n",
    "# os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = token\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_path, use_auth_token=token)\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_path,torch_dtype=torch.bfloat16,device_map=\"auto\", use_auth_token=token)\n",
    "# pipeline = transformers.pipeline(\"text-generation\", model=model,model_kwargs={\"torch_dtype\": torch.float16,\"quantization_config\": {\"load_in_4bit\": True},\"low_cpu_mem_usage\": True,}, tokenizer=tokenizer)s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T17:58:37.208741Z",
     "iopub.status.busy": "2024-12-06T17:58:37.208357Z",
     "iopub.status.idle": "2024-12-06T17:58:37.215874Z",
     "shell.execute_reply": "2024-12-06T17:58:37.214853Z",
     "shell.execute_reply.started": "2024-12-06T17:58:37.208708Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_inference(prompt):\n",
    "  messages = [\n",
    "    {\"role\": \"system\", \"content\": \".تو یک دستیار ویرایشگر متن های فارسی هستی\"},\n",
    "    {\"role\": \"user\", \"content\": \"\"\"{prompt}\"\"\".format(prompt = prompt)},\n",
    "  ]\n",
    "\n",
    "  prompt = f\"### Human:{prompt}\\n### Assistant:\"\n",
    "\n",
    "\n",
    "  inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "  generation_config = GenerationConfig(\n",
    "        do_sample=True,\n",
    "        top_k=1,\n",
    "        temperature=0.5,\n",
    "        max_new_tokens=2300,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "  outputs = model.generate(**inputs, generation_config=generation_config)\n",
    "  return(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T17:58:42.111974Z",
     "iopub.status.busy": "2024-12-06T17:58:42.111645Z",
     "iopub.status.idle": "2024-12-06T17:58:42.386797Z",
     "shell.execute_reply": "2024-12-06T17:58:42.385804Z",
     "shell.execute_reply.started": "2024-12-06T17:58:42.111944Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>true_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>شعاع دایره نصف قطر دایره است. گزینه ها: ا)درست...</td>\n",
       "      <td>ا</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>نصف عددی را با ۵ جمع کردیم حاصل ۱۲ شد . آن عدد...</td>\n",
       "      <td>ا</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>مساحت مستطیلی ۲۰ سانتی متر مربع است. اندازهی ض...</td>\n",
       "      <td>ا</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>مساحت مستطیلی ۲۰ سانتی متر مربع است. اندازهی ض...</td>\n",
       "      <td>ب</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>عدد 8 از 10 کوچکتر است. گزینه ها: ا)درست است  ...</td>\n",
       "      <td>ا</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question true_answer\n",
       "0  شعاع دایره نصف قطر دایره است. گزینه ها: ا)درست...           ا\n",
       "1  نصف عددی را با ۵ جمع کردیم حاصل ۱۲ شد . آن عدد...           ا\n",
       "2  مساحت مستطیلی ۲۰ سانتی متر مربع است. اندازهی ض...           ا\n",
       "3  مساحت مستطیلی ۲۰ سانتی متر مربع است. اندازهی ض...           ب\n",
       "4  عدد 8 از 10 کوچکتر است. گزینه ها: ا)درست است  ...           ا"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel(\"/kaggle/input/school-data/elem_q.xlsx\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T17:58:45.218126Z",
     "iopub.status.busy": "2024-12-06T17:58:45.217736Z",
     "iopub.status.idle": "2024-12-06T17:58:45.222647Z",
     "shell.execute_reply": "2024-12-06T17:58:45.221660Z",
     "shell.execute_reply.started": "2024-12-06T17:58:45.218098Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "PROMPT_FEW = \"\"\"\n",
    "در این وظیفه باید سوالات مربوط به ریاضیات مدارس ابتدایی را پاسخ بدهی. نحوه پاسخ دهی گزینه ا یا گزینه ب است.\n",
    "به مثالهای زیر توجه کن:\n",
    "\n",
    "  مثال 1:\n",
    "      question: شعاع دایره نصف قطر دایره است. گزینه ها: ا)درست است. ب)غلط است.\n",
    "      answer: ا\n",
    "\n",
    "\n",
    "  مثال 2:\n",
    "      question: نصف عددی را با ۵ جمع کردیم حاصل ۱۲ شد . آن عدد کدام است؟ گزینه ها: ا)14 ب)9\n",
    "      answer: ا\n",
    "\n",
    "\n",
    "  مثال 3:\n",
    "      question: مساحت مستطیلی ۲۰ سانتی متر مربع است. اندازهی ضلعها را طوری انتخاب کن که  محیط مستطیل ۱۸  باشد. گزینه ها: ا) عرض 4 و طول 5   ب) عرض 3 و طول 8\n",
    "      answer: ا\n",
    "\n",
    "\n",
    "\n",
    "  فرمت خروجی:\n",
    "  فرمت خروجی شما باید یک تاپل  باشد، که در آن هر تاپل از سوال و پاسخی که تشخیص داده ای تشکیل شده باشد.\n",
    "\n",
    "  \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T19:09:35.435978Z",
     "iopub.status.busy": "2024-12-06T19:09:35.435096Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i:  0\n",
      "i:  1\n",
      "i:  2\n",
      "i:  3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "all_response = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    print('i: ',index)\n",
    "    question = row['question']\n",
    "    true_answer = row['true_answer']\n",
    "\n",
    "    prompt_arman = f\"\"\"\n",
    "    شرح وظیفه:\n",
    "    {PROMPT_FEW}\n",
    "\n",
    "    ورودی:\n",
    "    {question}\n",
    "    \"\"\"\n",
    "    response = get_inference(prompt_arman)\n",
    "\n",
    "    all_response.append({'question':question , 'true_answer':true_answer , 'response':response})\n",
    "    np.save(f'/kaggle/working/school_maral.npy', np.array(all_response, dtype=object))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6235504,
     "sourceId": 10108043,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
